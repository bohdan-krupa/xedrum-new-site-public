"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[512],{560:(e,a,t)=>{t.d(a,{d:()=>i});let i=[{id:"healthcare-mvp-patient-imaging",title:"AI-Powered Healthcare MVP for Patient Imaging Insights",description:"A New York-based healthcare MVP that helps patients better understand their medical imaging results through AI-assisted explanations in plain, human-readable language.",tags:["Healthcare","AI/ML","Mobile App","HIPAA","RAG"],goals:["Build HIPAA-aware AI architecture","Implement RAG architecture for verified medical sources","Create MVP to validate user demand","Prepare for clinician-in-the-loop workflows"],imageSrc:"/images/caseStudies/case AI-Powered Healthcare MVP for Patient Imaging Insights.png",caseCardBgSrc:"/images/caseStudies/case AI-Powered Healthcare MVP for Patient Imaging Insights.png",industry:"Healthcare",location:"USA New York",size:"5 people",duration:"6 months",budget:"$35K",projectOverview:"A New York-based healthcare founder approached Xedrum to build a B2C healthcare MVP that helps patients better understand their medical imaging results. The core idea was simple but powerful: Patients upload medical images such as X-rays or scans and receive AI-assisted explanations in plain, human-readable language. The goal was not to replace doctors, but to reduce anxiety, confusion, and unnecessary follow-up questions by helping patients interpret results before or after clinical visits. The product was designed as a mobile-first MVP, focused on speed to market, HIPAA-aware architecture, and future scalability.",ourApproach:"We treated this project as both a healthcare MVP and an AI product foundation, even though AI was not intended to be a final diagnostic authority. Our approach focused on: Building a HIPAA-aware AI architecture, ensuring secure handling of PHI, encrypted data storage, controlled access, and audit-ready workflows. Implementing a RAG architecture, allowing AI responses to be grounded in verified medical sources, guidelines, and structured knowledge rather than raw model output. Creating an MVP that could quickly validate user demand with real patients. Preparing the system for clinician-in-the-loop workflows, future clinical partnerships, and deeper AI validation. Instead of starting with heavy AI training or custom medical models, we focused on practical AI integration, strong prompt orchestration, and reliable workflows that could evolve over time.",problem:"Patients regularly receive medical imaging results that are: Hard to understand without medical training, Delivered with minimal explanation, Stress-inducing and unclear, especially outside clinic hours. From the business side, the founder faced several challenges: Doctors and clinics don't have time to answer repetitive patient questions, Building a healthcare product requires careful compliance and wording, Overpromising AI capabilities could create legal and trust risks, Speed mattered more than building a 'perfect' AI model from day one. The challenge was to balance AI usefulness with healthcare responsibility, while still delivering a compelling consumer experience.",solution:{title:"Healthcare MVP with AI-Assisted Insights",description:"We delivered a Healthcare MVP with AI-assisted insights, designed for clarity, safety, and future expansion.",features:[{title:"AI-Assisted Image Explanation",description:"Patients can upload X-rays or other medical images. The AI provides educational explanations in simple language, focusing on general observations and common patterns, always framed as informational and not diagnostic."},{title:"Smart Context Layer",description:"Users can add context such as symptoms or doctor notes. AI uses this input to tailor explanations and highlight what questions patients may want to ask their physician."},{title:"Medical-Safe AI Prompting",description:"We implemented a carefully structured AI layer that avoids diagnosis or treatment advice, uses disclaimers and healthcare-safe language, and prioritizes clarity over certainty. This made the AI useful while remaining compliant and trustworthy."},{title:"Clean Patient-First UX",description:"The app was designed for non-technical users with simple upload flow, clear visual feedback, and human-friendly explanations instead of medical jargon."},{title:"Scalable & Compliant Architecture",description:"HIPAA-aware data handling, secure cloud infrastructure, and modular backend ready for future AI model upgrades or clinician dashboards."}]},outcome:"The founder received a production-ready MVP that validated patient demand for AI-assisted medical explanations, created a strong foundation for future AI improvements, and avoided regulatory and trust pitfalls common in health AI products. Most importantly, the product proved that AI in healthcare doesn't need to diagnose to deliver real value. It can educate, guide, and empower patients when designed responsibly."},{id:"ai-fashion-social-mobile-app",title:"AI-Fashion Social Mobile App",description:"A Berlin-based fashion social mobile app for enthusiasts to share outfits, discover styles, and interact through core social features with AI-powered tagging.",tags:["Mobile App","Social Media","AI/LLM","iOS","Beta"],goals:["Complete and stabilize inherited codebase","Implement AI-assisted tagging via LLM API","Ship production-ready mobile experience","Build scalable infrastructure with cost trade-offs"],imageSrc:"/images/caseStudies/case AI-Fashion Social Mobile App.png",caseCardBgSrc:"/images/caseStudies/case AI-Fashion Social Mobile App.png",industry:"Fashion/Social Media",location:"Germany, Berlin",size:"4 people",duration:"Ongoing",budget:"$25K",projectOverview:"We partnered with a Berlin-based founder building a fashion social mobile app for enthusiasts to share outfits, discover styles, and interact through core social features. Xedrum provided a dedicated product team (4 people) to take over existing early work, complete the MVP, implement an AI-powered tagging feature via an LLM API, and bring the product to production-ready quality. A key milestone was delivering a working beta to Apple TestFlight within a defined timeframe and budget, while preparing scalable infrastructure for growth.",ourApproach:"This was a startup-style engagement: move fast, ship a stable beta, and design the architecture to scale without burning money. Our approach focused on: Completing and stabilizing an inherited codebase, improving maintainability and delivery speed. Implementing AI-assisted tagging (LLM API) to improve content organization and discovery. Shipping a production-ready mobile experience, aligned with social app expectations (feeds, profiles, interactions). Building scalable infrastructure with cost trade-offs in mind (ready to grow, but lean for early-stage usage). Setting up monitoring and maintenance workflows to keep the app stable post-launch. Staying highly responsive to a startup environment with flexible hours and proactive problem solving. When issues appeared (including developer fit), we handled it quickly by swapping developers fast and smoothly, keeping delivery on track.",problem:"The founder needed a reliable partner to: Add a meaningful AI feature (not 'AI for hype'), specifically automatic tagging to help users categorize and discover fashion content. Take over partially completed work from another developer and finish the MVP. Deliver a working beta quickly, without sacrificing core quality. Build an infrastructure that would be scalable, but still optimized for early-stage budgets. Ensure ongoing maintenance, monitoring, and feature rollouts as the product evolves.",solution:{title:"Working Beta and Product Foundation",description:"We delivered a working beta and product foundation that included:",features:[{title:"AI-Powered Tagging (LLM Integration)",description:"We implemented AI-driven tagging via an LLM API to support automatic tagging of user-generated fashion images/content, improved content organization and searchability, and better discovery experiences for users browsing styles and categories. This feature helped the app feel smarter and more 'social-feed ready' without requiring a complex custom ML pipeline at MVP stage."},{title:"Full-Stack Product Delivery",description:"We completed both frontend and backend development, turning early work into a cohesive product with stable performance and clean workflows."},{title:"Scalable Infrastructure with Cost Trade-Offs",description:"We designed infrastructure to handle expected growth while keeping early-stage costs under control, with clear upgrade paths as traction increases."},{title:"Monitoring + Maintenance Setup",description:"We set up monitoring and support processes to detect issues early and keep the app stable during testing and rollouts."},{title:"Ongoing Feature Rollouts + Startup Guidance",description:"We supported the founder with best-practice advice, product decisions, and a flexible roadmap approach as priorities shifted."}]},outcome:"Delivered a working app on Apple TestFlight within the planned timeframe and budget. Strong client feedback around proactivity, responsiveness, and developer quality. Fast resolution when team adjustments were needed, keeping momentum without disruption."},{id:"cloud-ai-etl-platform-agriculture",title:"Cloud-Based AI & ETL Platform for Agricultural Machine Learning",description:"A cloud-native system capable of orchestrating AI workloads, managing data pipelines, and storing results for an AgriTech company specializing in machine learning for field crop analysis.",tags:["AI/ML","Cloud Infrastructure","AWS","ETL","Data Pipeline"],goals:["Create robust execution layer for AI and data pipelines","Design modular system architecture on AWS","Support full lifecycle of AI workloads","Introduce strong observability and control mechanisms"],imageSrc:"/images/caseStudies/case_Cloud_Based_AI_&_ETL_Platform_for_Agricultural_Machine_Learning.png",caseCardBgSrc:"/images/caseStudies/case_Cloud_Based_AI_&_ETL_Platform_for_Agricultural_Machine_Learning.png",industry:"AgriTech",location:"Israel",size:"3 people",duration:"3 months",budget:"$30K",projectOverview:"We collaborated with a European AgriTech company specializing in the application of machine learning and deep learning for field crop analysis. Their products relied on AI models that process large datasets and require reliable execution at scale. Xedrum was engaged to design and build a cloud-native system capable of orchestrating AI workloads, managing data pipelines, and storing results in a structured and accessible way. The goal was to create a stable backbone for current ML products while leaving room for future growth and experimentation.",ourApproach:"From the start, we approached this engagement as an AI infrastructure project, not just a backend implementation. Our focus was on: Creating a robust execution layer for AI and data pipelines, capable of handling compute-heavy jobs. Designing a modular system architecture on AWS that could later be adapted to other cloud providers if needed. Supporting the full lifecycle of AI workloads, from data ingestion to execution and output delivery. Introducing strong observability and control mechanisms for background jobs and long-running processes. Working in tight collaboration with the client's technical leadership through structured sprints and regular reviews. Rather than over-optimizing for a single model or workflow, we built a flexible foundation that could support evolving AI use cases in agriculture.",problem:"The client needed a centralized system to: Trigger and manage ML and deep learning jobs in a consistent way. Process and store large volumes of agricultural data efficiently. Work with both relational and non-relational data stores, depending on the workload. Schedule and monitor long-running jobs without manual intervention. Ensure the platform was stable, maintainable, and production-ready. Without this foundation, scaling AI solutions across different products and datasets would have been difficult and costly.",solution:{title:"Cloud-Based AI Execution Platform",description:"We delivered a cloud-based AI execution platform with the following capabilities:",features:[{title:"AI-Driven ETL and Workload Execution",description:"The system allows users to submit jobs via APIs, execute data-intensive AI workloads, and automatically persist results for downstream use. This created a repeatable and reliable workflow for running ML models in production."},{title:"Scalable AWS Infrastructure",description:"We built the platform using core AWS services such as EC2, AWS Batch, Lambda, S3, RDS (PostgreSQL), and DynamoDB. Each component was selected based on performance, scalability, and cost considerations."},{title:"Job Scheduling, Queueing, and Visibility",description:"Background jobs are scheduled and queued automatically, with monitoring in place to track execution progress, performance, and failures. This gave the team clear insight into system behavior at all times."},{title:"API-First System Design",description:"All core operations, including data upload, job execution, and result retrieval, are exposed through APIs. This made the platform easy to integrate with existing ML pipelines and future applications."},{title:"Operational UI",description:"We also delivered a lightweight user interface built with a modern frontend framework, allowing non-infrastructure users to monitor jobs and system status without touching cloud resources directly."}]},outcome:"A fully functional AI and ETL execution platform deployed on AWS. Reliable orchestration of machine learning and deep learning workloads. Centralized storage of outputs across object storage and databases. Predictable delivery through regular sprint planning and communication. Strong client confidence in the system design and technical execution."},{id:"rag-nl-to-sql-accounts-payable",title:"RAG-Powered Natural Language to SQL for Accounts Payable Automation",description:"A proof of concept using RAG architecture to enable non-technical users to interact with accounting data through natural language queries translated into secure SQL.",tags:["RAG","AI/ML","FinTech","SQL","Azure OpenAI"],goals:["Design secure AI interface for financial SQL database","Implement RAG to ground AI output in database schema","Prioritize accuracy, safety, and auditability","Deliver fast PoC with production readiness path"],imageSrc:"/images/caseStudies/case_RAG_Powered_Natural_Language_to_SQL_for_Accounts_Payable_Automation.png",caseCardBgSrc:"/images/caseStudies/case_RAG_Powered_Natural_Language_to_SQL_for_Accounts_Payable_Automation.png",industry:"Accounts Payable Automation",location:"Australia",size:"12 people",duration:"3 months",budget:"$15K",projectOverview:"We partnered with an Australia-based SaaS company operating in the Accounts Payable automation space to explore how AI could simplify and secure access to financial data stored in relational databases. The client's objective was to validate whether Natural Language queries could be reliably translated into SQL, enabling non-technical users to interact with accounting data without writing queries. Xedrum was engaged to deliver a focused proof of concept using a production-aware, security-first architecture.",ourApproach:"We approached this engagement as a RAG-driven AI data access project, rather than a generic NL-to-SQL experiment. Our focus was on: Designing a secure AI interface between natural language input and a financial SQL database. Implementing Retrieval-Augmented Generation (RAG) to ground AI output in database schema, metadata, and query rules. Prioritizing accuracy, safety, and auditability, critical for finance and accounting workflows. Delivering a fast PoC while maintaining a clear path to production readiness. Instead of relying on raw LLM output, we structured the system so the model reasons over retrieved schema context before generating SQL, significantly reducing errors and risk.",problem:"For financial SaaS platforms, enabling easy data access introduces several challenges: Business users need insights but lack SQL expertise. Direct AI-to-database interaction can lead to unsafe or incorrect queries. Accounting data demands strict control, validation, and traceability. Any AI solution must integrate cleanly with existing cloud infrastructure. The core challenge was proving that AI could generate accurate, secure SQL queries from natural language without compromising data integrity.",solution:{title:"RAG-Based NL-to-SQL PoC",description:"We delivered a working PoC and after MVP with the following capabilities:",features:[{title:"RAG-Based Natural Language to SQL",description:"A retrieval layer supplies the LLM with database schema and table relationships, column definitions and constraints, and predefined query boundaries. This context-driven approach enabled consistent, reliable SQL generation."},{title:"Secure Cloud Integration",description:"The solution integrated AWS RDS (SQL) as the data source and Azure OpenAI (GPT-4o) for language understanding and generation. Strict access controls ensured safe execution of generated queries."},{title:"API & Interface Layer",description:"We built a simple interface that accepts natural language questions, generates validated SQL statements, and returns structured results for downstream use."},{title:"Production-Aware Architecture",description:"Although delivered as a PoC, the system was designed with clear separation between AI, data, and execution layers, scalability and governance in mind, and readiness for future role-based access and logging."}]},outcome:"A successful NL-to-SQL proof of concept for Accounts Payable data. Secure and accurate SQL generation grounded in real schema context. On-time, on-budget delivery with clear and consistent communication. Strong alignment on long-term collaboration and product evolution."},{id:"rag-process-automation-fintech",title:"RAG-Powered Process Automation for a Fintech Platform",description:"A RAG-powered automation layer that enables teams to retrieve accurate information, automate internal workflows, and reduce manual processing across finance and operations.",tags:["RAG","FinTech","Process Automation","AI/ML","UK Compliance"],goals:["Design RAG architecture to ground AI in verified data","Automate repetitive operational workflows","Ensure UK financial compliance alignment","Deliver incremental value through automation"],imageSrc:"/images/caseStudies/case RAG-Powered Process Automation for a Fintech Platform.png",caseCardBgSrc:"/images/caseStudies/case RAG-Powered Process Automation for a Fintech Platform.png",industry:"FinTech",location:"London, UK",size:"12 people",duration:"3 months",budget:"$15K",projectOverview:"We worked with a UK-based FinTech company providing digital financial services to small and mid-sized businesses. As the platform scaled, internal teams increasingly relied on large volumes of operational, transactional, and compliance-related data spread across multiple systems. Xedrum was engaged to design and deliver a RAG-powered automation layer that enables teams to retrieve accurate information, automate internal workflows, and reduce manual processing across finance and operations. The focus was on practical AI adoption, improving efficiency without disrupting regulated FinTech processes.",ourApproach:"We approached this project as a FinTech-grade AI automation initiative, where accuracy, traceability, and security were as important as AI capability. Our approach focused on: Designing a Retrieval-Augmented Generation (RAG) architecture to ground AI responses in verified internal data. Automating repetitive operational workflows using AI-assisted decision support. Ensuring the solution aligned with UK financial and compliance expectations. Delivering incremental value through automation, rather than replacing core systems. Instead of building a standalone AI feature, we embedded RAG directly into existing workflows to act as an intelligent operations layer.",problem:"As the FinTech platform grew, teams faced several challenges: Key information was fragmented across databases, internal documentation, and reports. Operations and finance teams spent significant time manually querying data and preparing summaries. Compliance-related questions required cross-checking multiple sources. Existing tools were powerful but not easily accessible to non-technical users. The client needed a way to automate data retrieval and decision support without exposing sensitive systems or introducing compliance risks.",solution:{title:"RAG-Based Automation Solution",description:"We delivered a RAG-based automation solution designed specifically for FinTech operations:",features:[{title:"RAG-Powered Knowledge & Data Retrieval",description:"We implemented a RAG pipeline that retrieves structured data from internal databases, operational documentation and policies, and process-level metadata. The AI generates responses and summaries strictly grounded in retrieved sources, ensuring accuracy and auditability."},{title:"AI-Assisted Process Automation",description:"The system supports automation of internal operational queries, finance and reconciliation checks, and compliance-related information requests. This reduced manual effort and response time for recurring internal requests."},{title:"Secure, Controlled AI Access",description:"We implemented strict controls to ensure role-based access to data, separation between AI reasoning and data execution layers, and traceable outputs suitable for regulated environments."},{title:"API-First Integration",description:"The solution was integrated into existing systems via APIs, allowing teams to access AI-powered automation without changing their core workflows."},{title:"Production-Ready Architecture",description:"The system was designed with scalability in mind, clear logging and monitoring, and readiness for future expansion into customer-facing AI features."}]},outcome:"Reduced manual processing across finance and operations teams. Faster access to accurate, source-backed information. Improved consistency in compliance-related responses. A scalable AI automation foundation aligned with FinTech regulatory expectations."},{id:"ai-powered-saas-dashboard",title:"AI-powered SaaS Dashboard",description:"Learnly set out to transform online education with an intuitive e-learning platform. The vision was to make high-quality courses accessible and engaging, while tackling challenges related to student motivation, progress tracking, and flexible scheduling.",tags:["Node.js","TypeScript","React","AI Models (Python API)"],goals:["Improve performance and scalability","Enhance data visibility for end-users","Introduce AI-driven decision support tools"],imageSrc:"/images/caseStudies/case AI-powered SaaS Dashboard.png",caseCardBgSrc:"/images/caseStudies/case AI-powered SaaS Dashboard.png"}]},1094:(e,a,t)=>{t.d(a,{default:()=>o});var i=t(9244),n=t(9056),r=t(6229);function o(e){let{children:a,className:t,delay:o=0,y:s=16,once:l=!0,amount:c=.2}=e,d=(0,n.useRef)(null),[u,p]=(0,n.useState)(!1);return(0,n.useEffect)(()=>{let e=d.current;if(!e)return;if(window.matchMedia("(prefers-reduced-motion: reduce)").matches||!("IntersectionObserver"in window))return void p(!0);let a=new IntersectionObserver(e=>{let[t]=e;t.isIntersecting?(p(!0),l&&a.disconnect()):l||p(!1)},{threshold:c});return a.observe(e),()=>a.disconnect()},[c,l]),(0,i.jsx)("div",{ref:d,className:(0,r.cn)(t),style:{opacity:+!!u,transform:u?"translateY(0px)":"translateY(".concat(s,"px)"),transitionProperty:"opacity, transform",transitionDuration:"600ms",transitionTimingFunction:"cubic-bezier(0.22, 1, 0.36, 1)",transitionDelay:u?"".concat(o,"s"):"0s",willChange:"opacity, transform"},children:a})}},6229:(e,a,t)=>{t.d(a,{cn:()=>r});var i=t(650),n=t(4862);function r(){for(var e=arguments.length,a=Array(e),t=0;t<e;t++)a[t]=arguments[t];return(0,n.QP)((0,i.$)(a))}},9128:(e,a,t)=>{t.d(a,{default:()=>o});var i=t(9244),n=t(9056),r=t(6229);function o(e){let{children:a,className:t,fallback:o=null,rootMargin:s="300px 0px",amount:l=.01,once:c=!0}=e,d=(0,n.useRef)(null),[u,p]=(0,n.useState)(!1);return(0,n.useEffect)(()=>{let e=d.current;if(!e)return;if(!("IntersectionObserver"in window))return void p(!0);let a=new IntersectionObserver(e=>{let[t]=e;t.isIntersecting?(p(!0),c&&a.disconnect()):c||p(!1)},{rootMargin:s,threshold:l});return a.observe(e),()=>a.disconnect()},[l,c,s]),(0,i.jsx)("div",{ref:d,className:(0,r.cn)("min-h-[1px]",t),children:u?a:o})}}}]);